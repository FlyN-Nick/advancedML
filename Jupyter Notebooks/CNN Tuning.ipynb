{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow matplotlib graphics to display in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# for image dimension manipulation\n",
    "import numpy\n",
    "\n",
    "# import validation methods from scikit-learn\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# import the dataset and neural network layers from keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense, Flatten, Dropout, MaxPooling2D\n",
    "\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"MNIST is a famous dataset of images of handwritten numbers.\"\n",
    "\n",
    "# constants to describe the MNIST images\n",
    "NUM_ROWS = 28 \n",
    "NUM_COLUMNS = 28\n",
    "NUM_COLORS = 1 # grayscale\n",
    "IMG_SHAPE = (NUM_ROWS, NUM_COLUMNS, NUM_COLORS)\n",
    "\n",
    "# constant to describe the MNIST output labels\n",
    "# there are ten different numbers, 0-9\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "((images_train, labels_train), (images_test, labels_test)) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x14ae2eca0>"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a particular image\n",
    "matplotlib.pyplot.imshow(images_train[16], cmap='winter_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING MODEL\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# add convolutional layers\n",
    "model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=8, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(Conv2D(filters=8, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "# dense layers to consolidate information\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=8, activation='tanh'))\n",
    "\n",
    "# output layer to make the final decision on which number it is\n",
    "model.add(Dense(units=NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7148\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2790\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x14af34e80>"
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING MODEL\n",
    "\n",
    "# keras requires a color dimension, so we need to expand each image to have one\n",
    "images_3d_train = numpy.expand_dims(images_train, axis=3)\n",
    "\n",
    "# the labels need to be one-hot encoded, to match the ten outputs of our model\n",
    "labels_onehot_train = to_categorical(labels_train)\n",
    "\n",
    "# set up the model to be ready for training\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy')\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(images_3d_train, labels_onehot_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION W/ TEST SET\n",
    "\n",
    "# same reason as previous cell\n",
    "images_3d_test = numpy.expand_dims(images_test, axis=3)\n",
    "\n",
    "# get the predictions from the model (get the probability of each number for each image)\n",
    "predictions_test_onehot = model.predict(images_3d_test)\n",
    "\n",
    "# get the index that has the highest probability (what we actually care about)\n",
    "# the index just happens to be the same as the number\n",
    "predictions_test = numpy.argmax(predictions_test_onehot, axis=1)\n",
    "\n",
    "# this will be used to check for overfitting\n",
    "predictions_training_onehot = model.predict(images_3d_train)\n",
    "predictions_training = numpy.argmax(predictions_training_onehot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.6253\n",
      "training accuracy: 0.6143833333333333\n"
     ]
    }
   ],
   "source": [
    "# get accuracy\n",
    "print(f\"test accuracy: {accuracy_score(y_true=labels_test, y_pred=predictions_test)}\")\n",
    "print(f\"training accuracy: {accuracy_score(y_true=labels_train, y_pred=predictions_training)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.79623824 0.49673531 0.85884692 0.71377672 0.69402229 0.4691358\n",
      " 0.85254989 0.68495182 0.42251223 0.44386423]\n",
      "recall: [0.77755102 0.87136564 0.41860465 0.5950495  0.69755601 0.17040359\n",
      " 0.80271399 0.89883268 0.26591376 0.67393459]\n",
      "f score: [0.78678369 0.63275752 0.56286645 0.64902808 0.69578466 0.25\n",
      " 0.82688172 0.77745057 0.32640202 0.53522235]\n",
      "num examples of each num: [ 980 1135 1032 1010  982  892  958 1028  974 1009]\n"
     ]
    }
   ],
   "source": [
    "# get precision, recall, f-score, and number of examples of each digit\n",
    "(precision, recall, f_score, num_examples) = precision_recall_fscore_support(y_true=labels_test, y_pred=predictions_test)\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"f score: {f_score}\")\n",
    "print(f\"num examples of each num: {num_examples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Tuning the model to produce better results.\n",
    "\n",
    "I was able to increase accuracy from 0.6253 to 0.7927 by adding a dropout layer, changing the number of filters from 8 to 12, and using Adam as the optimizer instead of SGD.\n",
    "\n",
    "Generally, adding additional conv layers made the model perform worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING NEW MODEL\n",
    "\n",
    "new_model = Sequential()\n",
    "\n",
    "# add convolutional layers\n",
    "new_model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=12, kernel_size=3, strides=2, padding='same')) # 12 filters instead of 8\n",
    "model.add(Dropout(0.15)) # added dropout layer\n",
    "new_model.add(Conv2D(filters=12, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "# adding additional layers made the model perform worse\n",
    "# new_model.add(Conv2D(filters=12, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "# dense layers to consolidate information\n",
    "new_model.add(Flatten())\n",
    "new_model.add(Dense(units=12, activation='tanh'))\n",
    "\n",
    "# output layer to make the final decision on which number it is\n",
    "new_model.add(Dense(units=NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.1978\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7290\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x14b1c46d0>"
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING NEW MODEL\n",
    "\n",
    "# set up the new model to be ready for training\n",
    "new_model.compile(optimizer=Adam(), loss='categorical_crossentropy')\n",
    "\n",
    "# fit the new model to the training data\n",
    "new_model.fit(images_3d_train, labels_onehot_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION OF NEW MODEL W/ TEST SET\n",
    "\n",
    "# get the predictions from the model (get the probability of each number for each image)\n",
    "new_predictions_test_onehot = new_model.predict(images_3d_test)\n",
    "\n",
    "# get the index that has the highest probability (what we actually care about)\n",
    "# the index just happens to be the same as the number\n",
    "new_predictions_test = numpy.argmax(new_predictions_test_onehot, axis=1)\n",
    "\n",
    "# this will be used to check for overfitting\n",
    "new_predictions_training_onehot = new_model.predict(images_3d_train)\n",
    "new_predictions_training = numpy.argmax(new_predictions_training_onehot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.7927\n",
      "training accuracy: 0.7901666666666667\n",
      "precision: [0.79623824 0.49673531 0.85884692 0.71377672 0.69402229 0.4691358\n",
      " 0.85254989 0.68495182 0.42251223 0.44386423]\n",
      "recall: [0.77755102 0.87136564 0.41860465 0.5950495  0.69755601 0.17040359\n",
      " 0.80271399 0.89883268 0.26591376 0.67393459]\n",
      "f score: [0.78678369 0.63275752 0.56286645 0.64902808 0.69578466 0.25\n",
      " 0.82688172 0.77745057 0.32640202 0.53522235]\n",
      "num examples of each num: [ 980 1135 1032 1010  982  892  958 1028  974 1009]\n"
     ]
    }
   ],
   "source": [
    "# get accuracy\n",
    "print(f\"test accuracy: {accuracy_score(y_true=labels_test, y_pred=new_predictions_test)}\")\n",
    "print(f\"training accuracy: {accuracy_score(y_true=labels_train, y_pred=new_predictions_training)}\")\n",
    "\n",
    "# get precision, recall, f-score, and number of examples of each digit\n",
    "(new_precision, new_recall, new_f_score, new_num_examples) = precision_recall_fscore_support(y_true=labels_test, y_pred=predictions_test)\n",
    "print(f\"precision: {new_precision}\")\n",
    "print(f\"recall: {new_recall}\")\n",
    "print(f\"f score: {new_f_score}\")\n",
    "print(f\"num examples of each num: {new_num_examples}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}